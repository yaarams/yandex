{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Yaara Cohen - NLP_HW1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi3HmWo0-7Pq",
        "colab_type": "text"
      },
      "source": [
        "## Sentence reformulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFZtTMlzQgHW",
        "colab_type": "code",
        "outputId": "e30ad25a-7e5e-43f8-d921-9d94da43da48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!pip install fasttext\n",
        "!pip install scipy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (46.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.4)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyUFRaNC-7Pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import fasttext\n",
        "import scipy\n",
        "from gensim.models import KeyedVectors\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gk0Pxfc-7Pv",
        "colab_type": "text"
      },
      "source": [
        "Download FastText pretrained vectors for English: \n",
        "[cc.en300.vec.gz](https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz)\n",
        "\n",
        "And download Yelp! dataset composed of reviews: \n",
        "[Yelp.train.text](https://drive.google.com/file/d/1TAcfL091lKb2LipaUELFteZqJjQu-gMa/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ucm-EYZo-7Pv",
        "colab_type": "text"
      },
      "source": [
        "Load downloaded pretrained FastText vectors by gensim library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjoH2N2tjqUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yelp_download_link = \"https://docs.google.com/uc?export=download&id=1TAcfL091lKb2LipaUELFteZqJjQu-gMa\"\n",
        "fasttext_download_link = \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\"\n",
        "fname = 'cc.en.300.vec'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbf_55i7Gwv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O Yelp.train.text --no-check-certificate \"$yelp_download_link\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_uhUReuhGA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -nc $fasttext_download_link"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TSSG03rkaga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gunzip -k cc.en.300.vec.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfBAhS7lojca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "word_vectors = tqdm(KeyedVectors.load_word2vec_format('cc.en.300.vec'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRLrgEWc-7Pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fasttext.util\n",
        "fasttext.util.download_model('en', if_exists='ignore')\n",
        "ft = fasttext.load_model(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNPkf9bz-7Py",
        "colab_type": "text"
      },
      "source": [
        "Compute similarity of two words using gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVjpHMtS-7Py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We discussed different words, look and similarity of 'king' and 'queen' for example. Could you put it inot context?\n",
        "\n",
        "# word_vectors = KeyedVectors.load_word2vec_format(fname)\n",
        "# print(word_vectors.similarity('king', 'queen'))\n",
        "\n",
        "#from scipy import spatial as sp\n",
        "#king_v = ft.get_word_vector(\"king\")\n",
        "#queen_v = ft.get_word_vector(\"queen\")\n",
        "#sp.distance.cosine(king_v, queen_v)\n",
        "\n",
        "ft.get_nearest_neighbors('king', k=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP6mUyEj-7P0",
        "colab_type": "text"
      },
      "source": [
        "Sentence tokenization. Split Yelp! texts into separate tokens (words and punctuation marks) by space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "per6oPYo-7P1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#your code here\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "data_path = \"Yelp.train.text\"\n",
        "\n",
        "with open(data_path, 'r') as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "\n",
        "wpTokenizer = WordPunctTokenizer()\n",
        "tokens = list(map(wpTokenizer.tokenize, lines))\n",
        "tokens[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_unxLBG-7P3",
        "colab_type": "text"
      },
      "source": [
        "Try part of speech tagging using [NLTK POS-tagger](https://www.nltk.org/book/ch05.html).\n",
        "The function returns list of tuples (word, POS_tag)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm4KStIl-7P4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#your code here\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.pos_tag(tokens[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKAiBXox-7P6",
        "colab_type": "text"
      },
      "source": [
        "Can you find the most similar word to the given? Can you write a method that returns a list of tuples (word, similarity) in order of decreasing similarity?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjAdenRJ-7P6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#your code here\n",
        "most_similar_n = lambda word, topn: ft.get_nearest_neighbors(word, topn=topn)\n",
        "\n",
        "most_similar_n('dog', 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31tw_KrM-7P9",
        "colab_type": "text"
      },
      "source": [
        "Let's do the simplest reformulation task. We just want to reformulate some sentences replacing an ajective with a similar one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut3PTi7s-7P-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reformulate_sentence(sentence):\n",
        "    # Sentence tokenization\n",
        "    tokenized_sentence = tokenize_sentence(sentence)\n",
        "\n",
        "    # Part of speech tagging\n",
        "    POS_tagged_words = POS_tagging(tokenized_sentence)\n",
        "\n",
        "    reformulated_sentence_words = []\n",
        "    for word, pos_tag in POS_tagged_words:\n",
        "        # If the word is adjective...\n",
        "        if pos_tag in ['JJR', 'JJS', 'JJ']:\n",
        "            try:\n",
        "                # ...look for the word most similar to the given and replace it\n",
        "                new_word = most_similar_n(word, 1)[0][0]\n",
        "                reformulated_sentence_words.append(new_word)\n",
        "            except:\n",
        "                print('There is no {} word in FastText dictionary! ...'.format(word))\n",
        "        else:\n",
        "            reformulated_sentence_words.append(word)\n",
        "    # Join words list in a sentence\n",
        "    return ' '.join(reformulated_sentence_words)\n",
        "\n",
        "idx = 2\n",
        "print(lines[idx])\n",
        "print(reformulate_sentence(lines[idx]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTe0tHlj-7P_",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5IUdET8-7QA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcl94anK-7QC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from gensim.parsing.preprocessing import preprocess_string, remove_stopwords, strip_multiple_whitespaces, \\\n",
        "                                         strip_punctuation, stem_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxfO00H8-7QE",
        "colab_type": "text"
      },
      "source": [
        "VADER sentiment classifier from NLTK library. The range of sentiment is from -1 to 1 where -1 is negative, 0 is neutral and 1 is positive\n",
        "\n",
        "Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I3lz1dh-7QF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_analyzer = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvUIaPuI-7QH",
        "colab_type": "text"
      },
      "source": [
        "Read the dataset text file line by line and put lines into the list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBP8GzWc-7QH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#your code here\n",
        "lexicon_list = sentiment_analyzer.lexicon_file.split('\\r\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rplKa72R-7QJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqRQY1HR-7QL",
        "colab_type": "text"
      },
      "source": [
        "Read Yelp dataset from text file and get 1000 random sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRdFl0hG-7QL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#your code here\n",
        "sentences = lines[np.random.randint(0, 1000, (1000, 1))]\n",
        "\n",
        "processed_sentences = np.array([' '.join(preprocess_string(sentence[0], preprocessors)) for sentence in sentences])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnrjGoj6-7QO",
        "colab_type": "text"
      },
      "source": [
        "Compute average sentiment of 1000 sentences sentences set by VADER sentiment classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UGU2Gxa-7QO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#your code here\n",
        "get_average = lambda sentences: np.array([sentiment_analyzer.polarity_scores(s)['compound'] for s in sentences]).mean()\n",
        "\n",
        "get_average(processed_sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aee8sDP_-7QQ",
        "colab_type": "text"
      },
      "source": [
        "Reformulate sentences and compute average sentiment again. Try to come up with ways to make senteces more positive on average. What about more negative? Can you come up with some interesting experiment on this data with POS-tagged reformulations?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfPueDzZ-7QQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#your code here\n",
        "scores = np.array([sentiment_analyzer.polarity_scores(s)['compound'] for s in processed_sentences])\n",
        "positive_sentences = processed_sentences[scores > 0.5]\n",
        "print(positive_sentences[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P0XKlXGlOyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "negative_sentences = processed_sentences[scores < -0.2]\n",
        "print(negative_sentences[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}